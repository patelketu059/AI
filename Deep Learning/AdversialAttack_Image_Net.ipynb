{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RCV_P1_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThYtLOQklrK6"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import ntpath\n",
        "import sklearn.metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import IPython.display "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuyVe9KTluPE"
      },
      "source": [
        "# Load pretrained ResNet50 model\n",
        "# https://pytorch.org/docs/stable/torchvision/models.html\n",
        "# Tip: When loading model make sure pretrain argument set to True\n",
        "# Tip: Good resource for PyTorch projects: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use gpu device\n",
        "resnet50 = models.wide_resnet50_2(pretrained=True)\n",
        "model = resnet50 # load model from torchvision.models\n",
        "model = model.to(device)  # model operations are sent to GPU\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSHhnqqIlvuz",
        "outputId": "aae2982c-521a-4cb3-cdef-a7c36958f8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/My Drive/Colab Notebooks/RCV/Images/*'"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUnGXWGAmcEo"
      },
      "source": [
        "def adversialAttack(image):\n",
        "  temp = np.asarray(image)\n",
        "  result = np.zeros(temp.shape)\n",
        "  height, width, _ = temp.shape\n",
        "  for r in range(height):\n",
        "    for c in range(width):\n",
        "      createNoise = random.random();\n",
        "      if createNoise < 0.30:\n",
        "        result[r][c] = [127, 87, 186] #Adding a random rgb color to pixels at randm\n",
        "      else:\n",
        "        result[r][c] = temp[r][c]\n",
        "\n",
        "  convertToImage = Image.fromarray(result.astype('uint8'), 'RGB')\n",
        "  return convertToImage"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED5-3j7ilzfR"
      },
      "source": [
        "# Create custom Dataset for your images\n",
        "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = []\n",
        "        self.true_vals = []\n",
        "        self.root_dir = root_dir\n",
        "        classes = glob.glob(root_dir)\n",
        "        label_dict = {\"Ost1.jpg\":9,\n",
        "                \"Ost2.jpg\":9,\n",
        "                \"HH1.jpg\":4,\n",
        "                \"HH2.jpg\":4,\n",
        "                \"HV1.jpg\":66,\n",
        "                \"HV2.jpg\":66,\n",
        "                \"Peacock1.jpg\":84,\n",
        "                \"Peacock2.jpg\":84,\n",
        "                \"G1.jpg\":366,\n",
        "                \"G2.jpg\":366}\n",
        "      \n",
        "        for c in classes:\n",
        "            self.dataset += [[c, label_dict[ntpath.basename(c)]]]\n",
        "            self.true_vals += [label_dict[ntpath.basename(c)]]\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_path, target = self.dataset[index]\n",
        "        image = Image.open(image_path)\n",
        "        image = adversialAttack(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        ''' Dont need this because transform is None\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "       '''\n",
        "        return image, target"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6wJmCiTl2JP"
      },
      "source": [
        "# Create a DataLoader for your dataset\n",
        "root_dir = path\n",
        "transform = None\n",
        "custom_dataset = CustomDataset(root_dir, transform)\n",
        "loader = DataLoader(custom_dataset, batch_size=1)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlyc-wHl23t",
        "outputId": "49c23384-548a-4a5e-f6d7-8ef177177d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "# Cycle through custom dataset and pass data into the model\n",
        "model.eval()\n",
        "loss = 0\n",
        "correct = 0\n",
        "pred_vals = []\n",
        "class_vals = [9, 4, 66, 84, 366, 1000]\n",
        "#other = 1000\n",
        "target_vals = []\n",
        "with torch.no_grad():\n",
        "  for (image, target) in loader:\n",
        "      image = image.to(device)\n",
        "      target = target.to(device)\n",
        "      target_vals += [target.cpu().numpy().item()]\n",
        "      \n",
        "\n",
        "      prediction = model(image)\n",
        "      loss += torch.nn.functional.nll_loss(prediction, target, reduction = 'sum').item()\n",
        "      pred = prediction.argmax(dim=1, keepdim = True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      index = prediction.cpu().data.numpy().argmax()\n",
        "      if index in class_vals:\n",
        "        pred_vals += [index]\n",
        "      else:\n",
        "        pred_vals += [1000]\n",
        "  accuracy = 100.* correct / len(loader.dataset)\n",
        "  confusion = sklearn.metrics.confusion_matrix(target_vals, pred_vals, labels = class_vals)\n",
        "  print(\"Accuracy: \",accuracy, \"%\")\n",
        "\n",
        "\n",
        "  precision = []\n",
        "  recall = []\n",
        "  fscore = []\n",
        "  for i in range(0, len(class_vals)):\n",
        "\n",
        "    recall += [confusion[i,i] / sum(confusion[:,i])]\n",
        "    if np.isnan([confusion[i,i] / sum(confusion[i,:])]):\n",
        "      precision += [0]\n",
        "    else:\n",
        "      precision += [confusion[i,i] / sum(confusion[i,:])]\n",
        "\n",
        "\n",
        "    if np.isnan((precision[i] * recall[i]) * 2/ (precision[i] + recall[i])):\n",
        "      fscore += [0]\n",
        "    else:\n",
        "      fscore += [(precision[i] * recall[i]) * 2/ (precision[i] + recall[i])]\n",
        "\n",
        "  confusion = np.insert(confusion, 0, [9,4,66,84,366,1000], axis = 1)\n",
        "  confusion = np.insert(confusion, 0, [-1,9,4,66,84,366,1000], axis = 0)\n",
        "  print(\"           Predicted Values\")\n",
        "  print(confusion)\n",
        "  print(\"       Target Values on the left\")  \n",
        "\n",
        "\n",
        "  for i in range(0, len(class_vals)):\n",
        "    print(\"Class Number: \", class_vals[i], \"has Precision : \", precision[i], \"and has recall: \", recall[i], \"and F1 score :\", fscore[i])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.0 %\n",
            "           Predicted Values\n",
            "[[  -1    9    4   66   84  366 1000]\n",
            " [   9    0    0    0    0    0    2]\n",
            " [   4    0    0    0    0    0    2]\n",
            " [  66    0    0    0    0    0    2]\n",
            " [  84    0    0    0    0    0    2]\n",
            " [ 366    0    0    0    0    0    2]\n",
            " [1000    0    0    0    0    0    0]]\n",
            "       Target Values on the left\n",
            "Class Number:  9 has Precision :  0.0 and has recall:  nan and F1 score : 0\n",
            "Class Number:  4 has Precision :  0.0 and has recall:  nan and F1 score : 0\n",
            "Class Number:  66 has Precision :  0.0 and has recall:  nan and F1 score : 0\n",
            "Class Number:  84 has Precision :  0.0 and has recall:  nan and F1 score : 0\n",
            "Class Number:  366 has Precision :  0.0 and has recall:  nan and F1 score : 0\n",
            "Class Number:  1000 has Precision :  0 and has recall:  0.0 and F1 score : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}