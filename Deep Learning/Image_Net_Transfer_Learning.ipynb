{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "RCV_P1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de6c842ccad5452f94d0288f2e2aff50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7be9dfe751474f5695fc8321b0d832bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e2932099f5c481fa3f2e0fe48f0bb0f",
              "IPY_MODEL_6e8dcebcad084e4b89a1d5a9286bfe37"
            ]
          }
        },
        "7be9dfe751474f5695fc8321b0d832bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e2932099f5c481fa3f2e0fe48f0bb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf06573b6aa6430e9561663738e722bd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 138223492,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 138223492,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c42c63960044293b3bb6c5cacd64a37"
          }
        },
        "6e8dcebcad084e4b89a1d5a9286bfe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c27bb451a2d43a68e046b137a3dd992",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 132M/132M [02:22&lt;00:00, 972kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aaf6890d0b4847f3968952f595ecb8ff"
          }
        },
        "bf06573b6aa6430e9561663738e722bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c42c63960044293b3bb6c5cacd64a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c27bb451a2d43a68e046b137a3dd992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aaf6890d0b4847f3968952f595ecb8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSXZ-TEPLXk8"
      },
      "source": [
        "### Problem Statement\n",
        "Using PyTorch, set up the pre-trained\n",
        "network ResNet50. Obtain 10 of your own images that are similar to ImageNet classes\n",
        "and classify them. Choose 10 images from 5 different classes (2 images per class).\n",
        "Report the confusion matrix, the accuracy, the f-score, precision and recall of your\n",
        "classifier. There should be 6 classes representing the 5 classes that your images belong\n",
        "to as well as an 6th â€™otherâ€™ class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guV8l808LXlD"
      },
      "source": [
        "### Load required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPfE6yf2LXlJ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import ntpath\n",
        "import sklearn.metrics\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDCk0_J5LXlq",
        "outputId": "8ef94999-388a-49f3-f9aa-0d7e5dee309b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "de6c842ccad5452f94d0288f2e2aff50",
            "7be9dfe751474f5695fc8321b0d832bc",
            "7e2932099f5c481fa3f2e0fe48f0bb0f",
            "6e8dcebcad084e4b89a1d5a9286bfe37",
            "bf06573b6aa6430e9561663738e722bd",
            "3c42c63960044293b3bb6c5cacd64a37",
            "1c27bb451a2d43a68e046b137a3dd992",
            "aaf6890d0b4847f3968952f595ecb8ff"
          ]
        }
      },
      "source": [
        "# Load pretrained ResNet50 model\n",
        "# https://pytorch.org/docs/stable/torchvision/models.html\n",
        "# Tip: When loading model make sure pretrain argument set to True\n",
        "# Tip: Good resource for PyTorch projects: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use gpu device\n",
        "resnet50 = models.wide_resnet50_2(pretrained=True)\n",
        "model = resnet50 # load model from torchvision.models\n",
        "model = model.to(device)  # model operations are sent to GPU\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de6c842ccad5452f94d0288f2e2aff50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=138223492.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-HeX9pSO3kb",
        "outputId": "4f60bfc1-efa4-4b7b-81bf-6df2790c3ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBe9RIROPXlS",
        "outputId": "7f5507c3-bf38-4552-d2fa-43b0879b522b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "path = '/content/drive/My Drive/Colab Notebooks/RCV/Images/*'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/RCV/Images/*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn02W5OKLXmE"
      },
      "source": [
        "# Create custom Dataset for your images\n",
        "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = []\n",
        "        self.true_vals = []\n",
        "        self.root_dir = root_dir\n",
        "        classes = glob.glob(root_dir)\n",
        "        label_dict = {\"Ost1.jpg\":9,\n",
        "                \"Ost2.jpg\":9,\n",
        "                \"HH1.jpg\":4,\n",
        "                \"HH2.jpg\":4,\n",
        "                \"HV1.jpg\":66,\n",
        "                \"HV2.jpg\":66,\n",
        "                \"Peacock1.jpg\":84,\n",
        "                \"Peacock2.jpg\":84,\n",
        "                \"G1.jpg\":366,\n",
        "                \"G2.jpg\":366}\n",
        "      \n",
        "        for c in classes:\n",
        "            self.dataset += [[c, label_dict[ntpath.basename(c)]]]\n",
        "            self.true_vals += [label_dict[ntpath.basename(c)]]\n",
        "        print(self.true_vals)\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_path, target = self.dataset[index]\n",
        "        image = Image.open(image_path)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        ''' Dont need this because transform is None\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "       '''\n",
        "        return image, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMHcy3ZbLXmc",
        "outputId": "b15a2523-a6dc-494a-b9c0-968d57b94ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create a DataLoader for your dataset\n",
        "root_dir = path\n",
        "transform = None\n",
        "custom_dataset = CustomDataset(root_dir, transform)\n",
        "loader = DataLoader(custom_dataset, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 9, 4, 4, 66, 66, 84, 84, 366, 366]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkHtMglYLXmy",
        "outputId": "bed8ea29-f9d8-4a8b-8d64-a3cde2cc290e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Cycle through custom dataset and pass data into the model\n",
        "model.eval()\n",
        "loss = 0\n",
        "correct = 0\n",
        "pred_vals = []\n",
        "class_vals = [9, 4, 66, 84, 366, 1000]\n",
        "#other = 1000\n",
        "target_vals = []\n",
        "with torch.no_grad():\n",
        "  for (image, target) in loader:\n",
        "      image = image.to(device)\n",
        "      target = target.to(device)\n",
        "      target_vals += [target.cpu().numpy().item()]\n",
        "\n",
        "\n",
        "      prediction = model(image)\n",
        "      loss += torch.nn.functional.nll_loss(prediction, target, reduction = 'sum').item()\n",
        "      pred = prediction.argmax(dim=1, keepdim = True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      index = prediction.cpu().data.numpy().argmax()\n",
        "      if index in class_vals:\n",
        "        pred_vals += [index]\n",
        "      else:\n",
        "        pred_vals += [1000]\n",
        "  accuracy = 100.* correct / len(loader.dataset)\n",
        "  confusion = sklearn.metrics.confusion_matrix(target_vals, pred_vals, labels = class_vals)\n",
        "  print(\"Accuracy: \",accuracy, \"%\")\n",
        "I \n",
        "\n",
        "  precision = []\n",
        "  recall = []\n",
        "  fscore = []\n",
        "  for i in range(0, len(class_vals)):\n",
        "\n",
        "    recall += [confusion[i,i] / sum(confusion[:,i])]\n",
        "    if np.isnan([confusion[i,i] / sum(confusion[i,:])]):\n",
        "      precision += [0]\n",
        "    else:\n",
        "      precision += [confusion[i,i] / sum(confusion[i,:])]\n",
        "\n",
        "\n",
        "    if np.isnan((precision[i] * recall[i]) * 2/ (precision[i] + recall[i])):\n",
        "      fscore += [0]\n",
        "    else:\n",
        "      fscore += [(precision[i] * recall[i]) * 2/ (precision[i] + recall[i])]\n",
        "\n",
        "  confusion = np.insert(confusion, 0, [9,4,66,84,366,1000], axis = 1)\n",
        "  confusion = np.insert(confusion, 0, [-1,9,4,66,84,366,1000], axis = 0)\n",
        "  print(\"           Predicted Values\")\n",
        "  print(confusion)\n",
        "  print(\"       Target Values on the left\")  \n",
        "\n",
        "\n",
        "  for i in range(0, len(class_vals)):\n",
        "    print(\"Class Number: \", class_vals[i], \"has Precision : \", precision[i], \"and has recall: \", recall[i], \"and F1 score :\", fscore[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  70.0 %\n",
            "           Predicted Values\n",
            "[[  -1    9    4   66   84  366 1000]\n",
            " [   9    2    0    0    0    0    0]\n",
            " [   4    0    1    0    0    0    1]\n",
            " [  66    0    0    1    0    0    1]\n",
            " [  84    0    0    0    2    0    0]\n",
            " [ 366    0    0    0    0    1    1]\n",
            " [1000    0    0    0    0    0    0]]\n",
            "       Target Values on the left\n",
            "Class Number:  9 has Precision :  1.0 and has recall:  1.0 and F1 score : 1.0\n",
            "Class Number:  4 has Precision :  0.5 and has recall:  1.0 and F1 score : 0.6666666666666666\n",
            "Class Number:  66 has Precision :  0.5 and has recall:  1.0 and F1 score : 0.6666666666666666\n",
            "Class Number:  84 has Precision :  1.0 and has recall:  1.0 and F1 score : 1.0\n",
            "Class Number:  366 has Precision :  0.5 and has recall:  1.0 and F1 score : 0.6666666666666666\n",
            "Class Number:  1000 has Precision :  0 and has recall:  0.0 and F1 score : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}